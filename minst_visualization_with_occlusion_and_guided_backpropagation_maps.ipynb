{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_iters = 5000  # Number of training batches\n",
    "batch_size = 128       # Batch size\n",
    "\n",
    "n_input = 784   # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv2D wrapper, with bias and relu activation\n",
    "def conv2d(x, W, b, name, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x,name=name)\n",
    "\n",
    "# MaxPool2D wrapper\n",
    "def maxpool2d(x, name, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME',name=name)\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1],name=\"reshapedInput\")\n",
    "\n",
    "    # Convolution Layer 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'],name=\"conv1\")\n",
    "    conv1 = maxpool2d(conv1, k=2,name=\"maxpool1\")\n",
    "    #print(conv1.get_shape())\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'],name=\"conv2\")\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2,name=\"maxpool2\")\n",
    "    #print(conv2.get_shape())\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'],name=\"last10nodes\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer weights\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 16 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n",
    "    # 5x5 conv, 32 inputs, 32 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n",
    "    # fully connected, 7*7*32 inputs, 128 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*32, 128])),\n",
    "    # fully connected, 128 inputs, 10 outputs\n",
    "    'wd2': tf.Variable(tf.random_normal([128, 10])),\n",
    "    'out': tf.Variable(tf.random_normal([10, n_classes]))\n",
    "}\n",
    "\n",
    "# Layer biases\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([16])),\n",
    "    'bc2': tf.Variable(tf.random_normal([32])),\n",
    "    'bd1': tf.Variable(tf.random_normal([128])),\n",
    "    'bd2': tf.Variable(tf.random_normal([10])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases)\n",
    "y_pred = tf.nn.softmax(logits=pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100, Minibatch Loss= 789.160278, Training Accuracy= 0.75781, Validation Accuracy= 0.76433\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "best_valid_acc=0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            # Calculate batch loss and accuracy       \n",
    "            loss, acc= sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            valid_acc=sess.run(accuracy, feed_dict={x: mnist.test.images[:3000],\n",
    "                                                   y: mnist.test.labels[:3000]})\n",
    "            \n",
    "            #if (best_valid_acc<valid_acc) and (acc-valid_acc<=0.03):\n",
    "                #tf.train.Saver().save(sess, \"/tmp/model.ckpt\")\n",
    "                #best_valid_acc=valid_acc\n",
    "            \n",
    "            print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)+ \", Validation Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(valid_acc))\n",
    "        step += 1\n",
    "    print(\"Training Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy after Training:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[3001:],\n",
    "                                      y: mnist.test.labels[3001:]}))\n",
    "    \n",
    "    #tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "    #print(\"Testing Accuracy Corresponding to Best Validation:\", \\\n",
    "        #sess.run(accuracy, feed_dict={x: mnist.test.images[3001:],\n",
    "                                      #y: mnist.test.labels[3001:]}))\n",
    "    \n",
    "    tf.train.Saver().save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "'''\n",
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm\n",
    "\n",
    "def plot_image(image):\n",
    "    # Normalize the image so pixels are between 0.0 and 1.0\n",
    "    #img_norm = normalize_image(image)\n",
    "    \n",
    "    plt.imshow(np.reshape(image,[28,28]),  cmap=\"gray\")\n",
    "    #plt.imshow(np.reshape(image,[28,28]), cmap=\"gray\")\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOcclusion(im,roi_size):     \n",
    "    iters = (28-roi_size+1) \n",
    "    batch_size = iters**2+1\n",
    "    batch = np.ndarray([batch_size, 28, 28,1])\n",
    "    i = 0\n",
    "    for r in range(0,iters):\n",
    "        for c in range(0,iters):\n",
    "            imOc = np.copy(im)\n",
    "            imOc[r:r+roi_size-1,c:c+roi_size-1,0] = 0            \n",
    "            batch[i] = imOc           \n",
    "            i = i + 1\n",
    "    batch[i] = np.copy(im)\n",
    "    return batch\n",
    "\n",
    "def softmax(w):\n",
    "    w = np.array(w)\n",
    "    maxes = np.amax(w, axis=1)\n",
    "    maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "    e = np.exp(w-maxes) # The \"max trick\"\n",
    "    dist = e / np.sum(e, axis=1)[:,None]\n",
    "    return dist\n",
    "\n",
    "def createOcclusionHeatMap(img,roi_size):\n",
    "    with tf.Session() as sess:\n",
    "        tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "        model=sess.graph\n",
    "        occulationBatch=createOcclusion(img,roi_size)\n",
    "        feed_dict = {x: occulationBatch.reshape(len(occulationBatch),784)}\n",
    "        y_preds, preds = sess.run([y_pred, pred],feed_dict=feed_dict)\n",
    "        \n",
    "        cl=np.argmax(y_preds[-1])\n",
    "        print(\"Predicted digit of the image: \"+str(cl))\n",
    "        org_prob=np.max(y_preds[-1])\n",
    "        \n",
    "        count_map=np.zeros((28,28))\n",
    "        prob_map=np.zeros((28,28))\n",
    "        #prob_map=np.ones((28,28))\n",
    "        hmdim=(28-roi_size+1)\n",
    "        k=0\n",
    "        for i in range(hmdim):\n",
    "            for j in range(hmdim):\n",
    "                prob=y_preds[k][cl]\n",
    "                if prob<0.0:\n",
    "                    print(preds[k])\n",
    "                    print(y_preds[k])\n",
    "                k+=1\n",
    "                count_map[i:i+roi_size,j:j+roi_size]+=1.0\n",
    "                prob_map[i:i+roi_size,j:j+roi_size]+=prob\n",
    "                #for ip in range(i,i+roi_size):\n",
    "                #    for jp in range(j,j+roi_size):\n",
    "                #        prob_map[ip,jp]=min(prob,prob_map[ip,jp])\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                if count_map[i,j]>0:\n",
    "                    prob_map[i,j]/=count_map[i,j]\n",
    "                    prob_map[i,j]=1.0-prob_map[i,j]\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "        axes[0].matshow(img.reshape(28,28),cmap='gray')\n",
    "        pmap=axes[1].matshow(prob_map,cmap='Reds')\n",
    "        cbar=plt.colorbar(pmap, fraction=0.025, pad=0.0)\n",
    "        cbar.set_clim(0, 1.0)\n",
    "        cbar.draw_all()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250):\n",
    "    if np.argmax(mnist.test.labels[i])==8:\n",
    "        createOcclusionHeatMap(mnist.test.images[i].reshape(28,28,1),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(image, feature):\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "        model=sess.graph\n",
    "        tensor = model.get_tensor_by_name(\"last10nodes:0\")\n",
    "        best_p=tensor[0,feature]\n",
    "        gradient = tf.gradients(best_p, x)\n",
    "\n",
    "        feed_dict = {x: image.reshape(1,784)}\n",
    "        y, pred_v, grad = sess.run([  y_pred ,pred, gradient],feed_dict=feed_dict) \n",
    "\n",
    "        s_map=np.abs(grad[0].reshape(28,28))\n",
    "        s_map/=np.max(s_map)\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "        axes[0].matshow(image.reshape(28,28),cmap='gray')\n",
    "        pmap=axes[1].matshow(s_map,cmap='Reds')\n",
    "        cbar=plt.colorbar(pmap, fraction=0.025, pad=0.0)\n",
    "        cbar.set_clim(0, 1.0)\n",
    "        cbar.draw_all()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250):\n",
    "    if np.argmax(mnist.train.labels[i])==0:\n",
    "        saliency_map(mnist.train.images[i],np.argmax(mnist.train.labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"GuidedBackprop\")\n",
    "def _GuidedBackpropGrad(op, grad):\n",
    "    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros_like(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_relu_map(img,feature=0):    \n",
    "    with tf.Session() as sess:\n",
    "        tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "        model=sess.graph\n",
    "        \n",
    "        with tf.get_default_graph().gradient_override_map({'Relu': 'GuidedBackprop'}):\n",
    "            pred = conv_net(x, weights, biases)\n",
    "            gradient = tf.gradients(pred[0,feature], x)\n",
    "\n",
    "        feed_dict = {x: img.reshape(1,784)} \n",
    "        pred_v, grad=sess.run([pred,gradient],feed_dict=feed_dict) \n",
    "\n",
    "        img=img.reshape(28,28)\n",
    "        guided_backprop_map=np.abs(grad[0].reshape(28,28))\n",
    "        guided_backprop_map/=np.max(guided_backprop_map)\n",
    "\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "        axes[0].matshow(img.reshape(28,28),cmap='gray')\n",
    "        pmap=axes[1].matshow(guided_backprop_map.reshape(28,28),cmap='Reds')\n",
    "        cbar=plt.colorbar(pmap, fraction=0.025, pad=0.0)\n",
    "        cbar.set_clim(0, 1.0)\n",
    "        cbar.draw_all()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250):\n",
    "    if np.argmax(mnist.test.labels[i])==4:\n",
    "        guided_relu_map(mnist.test.images[i],np.argmax(mnist.test.labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "Visualizing and Understanding Convolutional Networks. M.D. Zeiler, R. Fergus. ECCV 2014. Arxiv 1311.2901 (Nov 28, 2013)\n",
    "\n",
    "Striving for simplicity: The all convolutional net. JT Springenberg, A Dosovitskiy, T Brox, M Riedmiller. arXiv preprint arXiv:1412.6806?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
