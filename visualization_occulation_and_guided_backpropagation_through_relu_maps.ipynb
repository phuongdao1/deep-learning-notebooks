{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_iters = 1000  # Number of training batches\n",
    "batch_size = 128       # Batch size\n",
    "\n",
    "n_input = 784   # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "#dropout = 1.0   # Dropout, probability to keep units\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "#keep_prob = tf.placeholder(tf.float32)             # node keeping probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv2D wrapper, with bias and relu activation\n",
    "def conv2d(x, W, b, name, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x,name=name)\n",
    "\n",
    "# Conv2D wrapper, with bias and relu activation\n",
    "def conv2d_norelu(x, W, b, name, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b, name=name)\n",
    "    return x\n",
    "\n",
    "# MaxPool2D wrapper\n",
    "def maxpool2d(x, name, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME',name=name)\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1],name=\"reshapedInput\")\n",
    "\n",
    "    # Convolution Layer 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'],name=\"conv1\")\n",
    "    conv1 = maxpool2d(conv1, k=2,name=\"maxpool1\")\n",
    "    print(conv1.get_shape())\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'],name=\"conv2\")\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2,name=\"maxpool2\")\n",
    "    print(conv2.get_shape())\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'],name=\"last10nodes\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 16)\n",
      "(?, 7, 7, 32)\n"
     ]
    }
   ],
   "source": [
    "# Layer weights\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 16 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n",
    "    # 5x5 conv, 32 inputs, 32 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n",
    "    # fully connected, 7*7*32 inputs, 128 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*32, 128])),\n",
    "    # fully connected, 128 inputs, 10 outputs\n",
    "    'wd2': tf.Variable(tf.random_normal([128, 10])),\n",
    "    'out': tf.Variable(tf.random_normal([10, n_classes]))\n",
    "}\n",
    "\n",
    "# Layer biases\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([16])),\n",
    "    'bc2': tf.Variable(tf.random_normal([32])),\n",
    "    'bd1': tf.Variable(tf.random_normal([128])),\n",
    "    'bd2': tf.Variable(tf.random_normal([10])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases)\n",
    "y_pred = tf.nn.softmax(logits=pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50, Minibatch Loss= 814.240356, Training Accuracy= 0.74219, Validation Accuracy= 0.71167\n",
      "Iter 100, Minibatch Loss= 434.048553, Training Accuracy= 0.81250, Validation Accuracy= 0.81267\n",
      "Iter 150, Minibatch Loss= 443.458588, Training Accuracy= 0.82031, Validation Accuracy= 0.85133\n",
      "Iter 200, Minibatch Loss= 298.115448, Training Accuracy= 0.87500, Validation Accuracy= 0.86867\n",
      "Iter 250, Minibatch Loss= 331.478882, Training Accuracy= 0.88281, Validation Accuracy= 0.87500\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "best_valid_acc=0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Set the new graph as the default.\n",
    "        #with tf.Graph().as_default():\n",
    "            \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy       \n",
    "            loss, acc= sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "            \n",
    "            valid_acc=sess.run(accuracy, feed_dict={x: mnist.test.images[:3000],\n",
    "                                                   y: mnist.test.labels[:3000],\n",
    "                                                   keep_prob: dropout})\n",
    "            \n",
    "            if (best_valid_acc<valid_acc) and (acc-valid_acc<=0.03):\n",
    "                tf.train.Saver().save(sess, \"/tmp/model.ckpt\")\n",
    "                best_valid_acc=valid_acc\n",
    "            \n",
    "            print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)+ \", Validation Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(valid_acc))\n",
    "        step += 1\n",
    "    print(\"Training Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy after Training:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[3001:],\n",
    "                                      y: mnist.test.labels[3001:],\n",
    "                                      keep_prob: dropout}))\n",
    "    \n",
    "    tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Testing Accuracy Corresponding to Best Validation:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[3001:],\n",
    "                                      y: mnist.test.labels[3001:],\n",
    "                                      keep_prob: dropout}))\n",
    "    \n",
    "    #tf.train.Saver().save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm\n",
    "\n",
    "def plot_image(image):\n",
    "    # Normalize the image so pixels are between 0.0 and 1.0\n",
    "    #img_norm = normalize_image(image)\n",
    "    \n",
    "    # Plot the image.\n",
    "    #plt.imshow(img_norm, interpolation='nearest')\n",
    "    #plt.imshow(image, interpolation='nearest')\n",
    "    plt.imshow(np.reshape(image,[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "    #plt.imshow(np.reshape(image,[28,28]), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted digit of the image: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116cd1b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def createOcclusion(im,roi_size):     \n",
    "    iters = (28-roi_size+1) \n",
    "    batch_size = iters**2+1\n",
    "    batch = np.ndarray([batch_size, 28, 28,1])\n",
    "    i = 0\n",
    "    for r in range(0,iters):\n",
    "        for c in range(0,iters):\n",
    "            imOc = np.copy(im)\n",
    "            imOc[r:r+roi_size-1,c:c+roi_size-1,0] = 0            \n",
    "            batch[i] = imOc           \n",
    "            i = i + 1\n",
    "    batch[i] = np.copy(im)\n",
    "    return batch\n",
    "\n",
    "def softmax(w):\n",
    "    w = np.array(w)\n",
    "    maxes = np.amax(w, axis=1)\n",
    "    maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "    e = np.exp(w-maxes) # The \"max trick\"\n",
    "    dist = e / np.sum(e, axis=1)[:,None]\n",
    "    return dist\n",
    "\n",
    "def createOcclusionHeatMap(img,roi_size):\n",
    "    with tf.Session() as sess:\n",
    "        tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "        model=sess.graph\n",
    "        occulationBatch=createOcclusion(img,roi_size)\n",
    "        #print(len(occulationBatch))\n",
    "        feed_dict = {x: occulationBatch.reshape(len(occulationBatch),784),keep_prob: dropout}\n",
    "        y_preds, preds = sess.run([y_pred, pred],feed_dict=feed_dict)\n",
    "        \n",
    "        cl=np.argmax(y_preds[-1])\n",
    "        print(\"predicted digit of the image: \"+str(cl))\n",
    "        org_prob=np.max(y_preds[-1])\n",
    "        \n",
    "        count_map=np.zeros((28,28))\n",
    "        prob_map=np.zeros((28,28))\n",
    "        hmdim=(28-roi_size+1)\n",
    "        k=0\n",
    "        for i in range(hmdim):\n",
    "            for j in range(hmdim):\n",
    "                prob=y_preds[k][cl]\n",
    "                if prob<0.0:\n",
    "                    print(preds[k])\n",
    "                    print(y_preds[k])\n",
    "                k+=1\n",
    "                count_map[i:i+roi_size,j:j+roi_size]+=1.0\n",
    "                prob_map[i:i+roi_size,j:j+roi_size]+=prob\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                if count_map[i,j]>0:\n",
    "                    prob_map[i,j]/=count_map[i,j]\n",
    "                    prob_map[i,j]=1-prob_map[i,j]\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "        axes[0].matshow(img.reshape(28,28),cmap='gray')\n",
    "        pmap=axes[1].matshow(prob_map)\n",
    "        #plt.colorbar(pmap,ax=axes[1])\n",
    "        plt.show()\n",
    "        #print(prob_map)\n",
    "        \n",
    "        #fig = plt.figure(figsize=(5,5))\n",
    "        #fig1 = fig.add_subplot(1,2,1)\n",
    "        #fig1.matshow(img.reshape(28,28),cmap='gray')\n",
    "        #fig2 = fig.add_subplot(1,2,2)\n",
    "        #im2=fig2.matshow(prob_map)\n",
    "        #plt.colorbar(im2)\n",
    "        #plt.show()\n",
    "        #plt.matshow(img.reshape(28,28),cmap='gray')\n",
    "        #plot_image(img)      \n",
    "        #plot_image(prob_map.reshape(784))\n",
    "        #plt.matshow(prob_map)\n",
    "        #plt.colorbar()\n",
    "        #plt.show() \n",
    "\n",
    "createOcclusionHeatMap(mnist.train.images[1005].reshape(28,28,1),5)\n",
    "\n",
    "#createOcclusion(mnist.test.images[3003].reshape(28,28,1),5)\n",
    "#with tf.Session() as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized_image\n",
      "(?, 28, 28, 1)\n",
      "(?, 14, 14, 16)\n",
      "(?, 7, 7, 32)\n",
      "xshape\n",
      "(?, 784)\n",
      "image shape\n",
      "(1, 784)\n",
      "before\n",
      "pred1\n",
      "[[ 1716.2800293   2962.16870117  9998.14941406  4468.24414062  3236.34375\n",
      "    783.60974121 -4095.41259766  3299.21728516  2446.92895508\n",
      "   2422.57910156]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "gradient\n",
      "image\n",
      "(1, 784)\n",
      "tensor\n",
      "image shape\n",
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYq3JFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e4e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kBThB5Ii/EBShB9IivADSf0P7r7sYH68eoAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c4e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros_like(grad))\n",
    "\n",
    "def guided_relu_map(img,feature=0):\n",
    "    \"\"\"\n",
    "    Find an image that maximizes the feature\n",
    "    given by the conv_id and feature number.\n",
    "\n",
    "    Parameters:\n",
    "    conv_id: Integer identifying the convolutional layer to\n",
    "             maximize. It is an index into conv_names.\n",
    "             If None then use the last fully-connected layer\n",
    "             before the softmax output.\n",
    "    feature: Index into the layer for the feature to maximize.\n",
    "    num_iteration: Number of optimization iterations to perform.\n",
    "    show_progress: Boolean whether to show the progress.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Inception model. This is done for each call of\n",
    "    # this function because we will add a lot to the graph\n",
    "    # which will cause the graph to grow and eventually the\n",
    "    # computer will run out of memory.\n",
    "    #model = inception.Inception()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.train.Saver().restore(sess, \"/tmp/model.ckpt\")\n",
    "        model=sess.graph\n",
    "        \n",
    "        # Reference to the tensor that takes the raw input image.\n",
    "        resized_image = model.get_tensor_by_name(\"reshapedInput:0\")\n",
    "        print(\"resized_image\")\n",
    "        print(resized_image.shape)\n",
    "\n",
    "        # Reference to the tensor for the predicted classes.\n",
    "        # This is the output of the final layer's softmax classifier.\n",
    "        #y_pred = model.y_pred\n",
    "        #print(\"y_pred\")\n",
    "        #print(y_pred.shape)\n",
    "        \n",
    "        tensor = model.get_tensor_by_name(\"last10nodes:0\")\n",
    "        #tensor = model.get_tensor_by_name(\"last10nodes:0\")\n",
    "        with tf.get_default_graph().gradient_override_map({'Relu': 'GuidedRelu'}):\n",
    "            #conv1 = conv2d_norelu(x, weights['wc1'], biases['bc1'],name=\"conv1\")\n",
    "            pred = conv_net(x, weights, biases, keep_prob)\n",
    "            y_pred = tf.nn.softmax(logits=pred)\n",
    "            \n",
    "            #loss1=tf.reduce_mean(tensor[:,feature])\n",
    "            #for i in range(10):\n",
    "                #if i!=feature:\n",
    "                    #loss1-=tf.maximum(tf.reduce_mean(tensor[:,i]),0)\n",
    "            ysoft = tf.nn.softmax(logits=pred)\n",
    "            #gradient = tf.gradients(tensor[0,feature], x)\n",
    "            gradient = tf.gradients(pred[0,feature], x)\n",
    "\n",
    "        # Generate a random image of the same size as the raw input.\n",
    "        # Each pixel is a small random value between 128 and 129,\n",
    "        # which is about the middle of the colour-range.\n",
    "        image_shape = resized_image.get_shape()\n",
    "        print(\"xshape\")\n",
    "        print(x.get_shape())\n",
    "        image=img.reshape(1,784)\n",
    "        print(\"image shape\")\n",
    "        print(image.shape)\n",
    "        #print(image[0])\n",
    "        #return 1\n",
    "\n",
    "        feed_dict = {x: image.reshape(1,784),keep_prob: dropout} \n",
    "        print(\"before\")\n",
    "        t_v,y, pred1,grad = sess.run([ tensor, y_pred ,pred,gradient],feed_dict=feed_dict) \n",
    "        print(\"pred1\")\n",
    "        print(pred1)\n",
    "        print(y)\n",
    "        print(\"gradient\")\n",
    "        #print(grad)\n",
    "        print(\"image\")\n",
    "        print(image.shape)\n",
    "        print(\"tensor\")\n",
    "\n",
    "        print(\"image shape\")\n",
    "        print(image.shape)\n",
    "        #print(\"grad shape\")\n",
    "        img=img.reshape(784)\n",
    "        img1=np.abs(grad[0].reshape(784))\n",
    "        img1/=np.max(img1)\n",
    "        img1[img1<=0.5]=0\n",
    "        '''\n",
    "        for i in range(784):\n",
    "            if img1[i]<=0.0 or img[i]<=0.1:\n",
    "                img1[i]=0\n",
    "        '''\n",
    "        plot_image(image.reshape(784))\n",
    "        plot_image(img1.reshape(784))\n",
    "\n",
    "guided_relu_map(mnist.test.images[990],np.argmax(mnist.test.labels[990]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized_image\n",
      "(?, 28, 28, 1)\n",
      "(?, 14, 14, 16)\n",
      "(?, 7, 7, 32)\n",
      "xshape\n",
      "(?, 784)\n",
      "image shape\n",
      "(1, 784)\n",
      "before\n",
      "pred1\n",
      "[[  157.13807678  2714.47290039  1155.82434082  2465.80029297\n",
      "    951.44024658  3025.89453125    33.35299301  -513.75793457\n",
      "   -105.44784546   798.03820801]]\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "gradient\n",
      "image\n",
      "(1, 784)\n",
      "tensor\n",
      "image shape\n",
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBThB5Ii/EBShB9IivADSRF+IKn/ApPmQPLFTPCRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ee8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5Rt7WU0kxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c30160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guided_relu_map(mnist.train.images[980],np.argmax(mnist.train.labels[980]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
